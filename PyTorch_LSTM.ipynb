{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Workflow for PyTorch Model Construction",
   "id": "48cf8e3165d89af8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tensor Attributes",
   "id": "851516d1bfcc42cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- shape, dtype, device\n",
   "id": "4c8dbb5e1c4b831c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_tensor = torch.rand(3, 4)\n",
    "print(sample_tensor, [sample_tensor.shape, sample_tensor.dtype, sample_tensor.device])"
   ],
   "id": "b1ee3f6659b78ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- numpy default arrays -> int64, float64\n",
    "- torch default tensors -> float32\n",
    "- tensor = torch.from_numpy(array).type(torch.float32)\n",
    "- array = tensor.numpy().astype(\"float64\")"
   ],
   "id": "360b8c31f09ef676"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy() # .astype(\"float64\")\n",
    "tensor.dtype, numpy_tensor.dtype"
   ],
   "id": "b5863ce0ee59be3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Device-agnostic code\n",
    "https://pytorch.org/docs/main/notes/cuda.html#device-agnostic-code"
   ],
   "id": "fc58ffcf5387ee2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Example')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "args = parser.parse_args()\n",
    "args.device = None\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "else:\n",
    "    args.device = torch.device('cpu')"
   ],
   "id": "f2500ba509f1d749",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data",
   "id": "d65fb3c67549c9dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- EDA\n",
    "- Preprocessing\n",
    "- Train/Validation/Test Split\n",
    "- Visualize"
   ],
   "id": "12a6329d6b91583b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "b95c57551114469a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Setup",
   "id": "c1b1b1b50af0ac39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "id": "d5267a45b1b77dc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train & Evaluate Model",
   "id": "2da0759f14efbd50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the loss function\n",
    "loss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n",
    "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))"
   ],
   "id": "583675e328da2e1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs (how many times the model will pass over the training data)\n",
    "epochs = 100\n",
    "\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    # Put model in training mode (this is the default state of a model)\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass on train data using the forward() method inside\n",
    "    y_pred = model_0(X_train)\n",
    "    # print(y_pred)\n",
    "\n",
    "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Zero grad of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Progress the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass on test data\n",
    "      test_pred = model_0(X_test)\n",
    "\n",
    "      # 2. Caculate loss on test data\n",
    "      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
    "\n",
    "      # Print out what's happening\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ],
   "id": "3a8e14e87878130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plot Training",
   "id": "34998245e535fa2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ],
   "id": "d4aa987b89cd8118"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "800dc5e0390f1418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Set the model in evaluation mode\n",
    "model_0.eval()\n",
    "\n",
    "# 2. Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  # 3. Make sure the calculations are done with the model and data on the same device\n",
    "  # in our case, we haven't setup device-agnostic code yet so our data and model are\n",
    "  # on the CPU by default.\n",
    "  # model_0.to(device)\n",
    "  # X_test = X_test.to(device)\n",
    "  y_preds = model_0(X_test)\n",
    "y_preds\n",
    "plot_predictions(predictions=y_preds)"
   ],
   "id": "5501f431c365a9b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save/Load Model",
   "id": "e37f3bad83bd1af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)\n",
    "!ls -l models/01_pytorch_workflow_model_0.pth\n",
    "\n"
   ],
   "id": "8a2638610f4e9bee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter Optimization",
   "id": "8f3cdc1cb31d9589"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
