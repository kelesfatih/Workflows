{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Workflow for PyTorch Model Construction",
   "id": "48cf8e3165d89af8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tensor Attributes",
   "id": "851516d1bfcc42cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- shape, dtype, device\n",
   "id": "4c8dbb5e1c4b831c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_tensor = torch.rand(3, 4)\n",
    "print(sample_tensor, [sample_tensor.shape, sample_tensor.dtype, sample_tensor.device])"
   ],
   "id": "b1ee3f6659b78ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- numpy default arrays -> int64, float64\n",
    "- torch default tensors -> float32\n",
    "- tensor = torch.from_numpy(array).type(torch.float32)\n",
    "- array = tensor.numpy().astype(\"float64\")"
   ],
   "id": "360b8c31f09ef676"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy() # .astype(\"float64\")\n",
    "tensor.dtype, numpy_tensor.dtype"
   ],
   "id": "b5863ce0ee59be3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Device-agnostic code\n",
    "https://pytorch.org/docs/main/notes/cuda.html#device-agnostic-code"
   ],
   "id": "fc58ffcf5387ee2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Example')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "args = parser.parse_args()\n",
    "args.device = None\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "else:\n",
    "    args.device = torch.device('cpu')"
   ],
   "id": "f2500ba509f1d749",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data",
   "id": "d65fb3c67549c9dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- EDA\n",
    "- Preprocessing\n",
    "- Train/Validation/Test Split\n",
    "- Visualize"
   ],
   "id": "12a6329d6b91583b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "b95c57551114469a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Setup",
   "id": "c1b1b1b50af0ac39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "hp = {\n",
    "    # Model Architecture Parameters\n",
    "    \"input_size\": 1, # Number of features\n",
    "    \"hidden_size\": 64, # Number of perceptron\n",
    "    \"num_layers\": 2,\n",
    "    \"output_dim\": 1,\n",
    "    \"dropout\": 0.2,\n",
    "    \"h0\": None,\n",
    "    \"c0\": None,\n",
    "    # Pre-Training Parameters\n",
    "    \"loss\": nn.MSELoss(),\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    # Training Parameters\n",
    "    \"batch_size\": 20,\n",
    "    \"num_epochs\": 15,\n",
    "}\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=hp[\"input_size\"], hidden_size=hp[\"hidden_size\"], num_layers=hp[\"num_layers\"],\n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(in_features=hp[\"hidden_size\"], out_features=hp[\"output_dim\"])\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(hp[\"num_layers\"], x.size(0), hp[\"hidden_size\"]).to(device)\n",
    "            c0 = torch.zeros(hp[\"num_layers\"], x.size(0), hp[\"hidden_size\"]).to(device)\n",
    "        output, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(output[:, -1, :])\n",
    "        return out, hn, cn\n",
    "\n",
    "model = LSTM().to(device)\n",
    "summary(model)"
   ],
   "id": "d5267a45b1b77dc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train & Evaluate Model",
   "id": "2da0759f14efbd50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_fn = hp[\"loss\"]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hp[\"learning_rate\"])"
   ],
   "id": "583675e328da2e1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def validate(model, val_loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.inference_mode():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            preds, _, _ = model(x_batch)\n",
    "            loss = loss_fn(preds, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            all_preds.append(preds.cpu().detach().numpy())\n",
    "            all_targets.append(y_batch.cpu().detach().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    rmse = np.sqrt(np.mean((all_targets - all_preds) ** 2))\n",
    "    mae = np.mean(np.abs(all_targets - all_preds))\n",
    "    return avg_loss, rmse, mae\n",
    "\n",
    "def plot_loss_curves(train_losses, val_losses):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss Curves Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train():\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(1, hp[\"num_epochs\"] + 1):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\") as t:\n",
    "            for x_batch, y_batch in t:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                y_pred, h0, c0 = model(x_batch, h0=hp[\"h0\"], c0=hp[\"c0\"])\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                h0 = h0.detach()\n",
    "                c0 = c0.detach()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Run validation and record loss\n",
    "        val_loss, val_rmse, val_mae = validate(model, val_loader, loss_fn)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch} Train Loss: {train_loss:.5f}\")\n",
    "        print(f\"Epoch {epoch} Validation Loss: {val_loss:.5f}, RMSE: {val_rmse:.5f}, MAE: {val_mae:.5f}\")\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"models/best_model.pth\")\n",
    "            print(\"Model saved\")\n",
    "\n",
    "    # After training, plot loss curves\n",
    "    plot_loss_curves(train_losses, val_losses)\n",
    "def test():\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(\"models/best_model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    y_pred_list = []\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            x = batch[0].to(device)\n",
    "            outputs, _, _ = model(x)\n",
    "            y_pred_list.append(outputs)\n",
    "\n",
    "    # Concatenate all predictions and obtain the final prediction tensor\n",
    "    y_pred = torch.cat(y_pred_list, dim=0)\n",
    "\n",
    "    # The true values correspond to the values following the sliding window in the raw array.\n",
    "    # Since X_test was created as: [raw[i-window_size:i, 0] for i in range(window_size, raw.shape[0])],\n",
    "    # the true values are raw[window_size:].\n",
    "    window_size = 50\n",
    "    y_true_np = raw[window_size:]  # raw is expected to be defined in the global scope as the scaled array\n",
    "    y_true = torch.from_numpy(y_true_np).type(torch.float32).to(device)\n",
    "\n",
    "    return y_pred, y_true\n",
    "\n",
    "def plot_results():\n",
    "    # Get predictions and true values from the test function\n",
    "    y_pred, y_true = test()\n",
    "\n",
    "    # Convert tensors to numpy arrays and flatten them\n",
    "    y_pred_np = y_pred.cpu().detach().numpy().flatten().reshape(-1, 1)\n",
    "    y_true_np = y_true.cpu().detach().numpy().flatten().reshape(-1, 1)\n",
    "\n",
    "    # Use the scaler stored in the DataPreparation instance to inverse transform\n",
    "    y_pred_original = df_instance.scaler.inverse_transform(y_pred_np).flatten()\n",
    "    y_true_original = df_instance.scaler.inverse_transform(y_true_np).flatten()\n",
    "\n",
    "    # Prepare DataFrame and plot with seaborn\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"Index\": range(len(y_true_original)),\n",
    "        \"True Value\": y_true_original,\n",
    "        \"Predicted Value\": y_pred_original\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=\"Index\", y=\"True Value\", data=df_plot, label=\"True\")\n",
    "    sns.lineplot(x=\"Index\", y=\"Predicted Value\", data=df_plot, label=\"Predicted\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.title(\"LSTM Predictions vs Original True Values\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "id": "3a8e14e87878130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "800dc5e0390f1418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Set the model in evaluation mode\n",
    "model_0.eval()\n",
    "\n",
    "# 2. Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  # 3. Make sure the calculations are done with the model and data on the same device\n",
    "  # in our case, we haven't setup device-agnostic code yet so our data and model are\n",
    "  # on the CPU by default.\n",
    "  # model_0.to(device)\n",
    "  # X_test = X_test.to(device)\n",
    "  y_preds = model_0(X_test)\n",
    "y_preds\n",
    "plot_predictions(predictions=y_preds)"
   ],
   "id": "5501f431c365a9b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save/Load Model",
   "id": "e37f3bad83bd1af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)\n",
    "!ls -l models/01_pytorch_workflow_model_0.pth\n",
    "\n"
   ],
   "id": "8a2638610f4e9bee",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
